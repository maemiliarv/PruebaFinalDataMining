Proyecto Final - MinerÃ­a de Datos

PredicciÃ³n de CancelaciÃ³n de Suscripciones (Churn) - Interconnect

DescripciÃ³n del proyecto
Este proyecto tiene como objetivo predecir la cancelaciÃ³n de suscripciones (churn) de clientes de la empresa Interconnect, permitiendo al equipo de marketing identificar usuarios en riesgo y aplicar estrategias de retenciÃ³n proactivas. Se ha desarrollado un modelo de machine learning siguiendo la metodologÃ­a CRISP-DM, utilizando datos de contratos, servicios, caracterÃ­sticas personales y hÃ¡bitos de consumo.

Dataset utilizado
contract.csv â€” InformaciÃ³n de contratos (tipo, duraciÃ³n, pagos).
internet.csv â€” Servicios de Internet y caracterÃ­sticas tÃ©cnicas.
personal.csv â€” Datos demogrÃ¡ficos y de segmentaciÃ³n.
phone.csv â€” Servicios telefÃ³nicos y lÃ­neas asociadas.

TecnologÃ­as y librerÃ­as
Python 3.10
Pandas, NumPy, Matplotlib, Seaborn
Scikit-learn
XGBoost
SHAP
Joblib

Estructura del repositorio
data/              # Datos originales (no subidos al repo)
model/             # Modelos entrenados (.joblib)
notebook/          # Notebook del proyecto
src/               # CÃ³digo auxiliar (opcional)
README.md             # Este archivo
requirements.txt      # Dependencias del proyecto
.gitignore            # Exclusiones de git (data, .ipynb_checkpoints, etc.)

MetodologÃ­a aplicada (CRISP-DM)
Business Understanding
DefiniciÃ³n del problema, hipÃ³tesis clave y KPI (AUC-ROC, F1-score).
Data Understanding
ExploraciÃ³n inicial, anÃ¡lisis de nulos, outliers y supuestos.
Data Preparation
UnificaciÃ³n de datasets, limpieza, imputaciÃ³n de nulos, encoding, escalado, creaciÃ³n de nuevas features (Tenure).
Modeling
Entrenamiento de 3 algoritmos:
Logistic Regression (baseline)
Random Forest (ensemble)
XGBoost (boosting - mejor desempeÃ±o)
ValidaciÃ³n con cross-validation (k=5) y manejo de desbalance con class_weight y scale_pos_weight.
Evaluation
ComparaciÃ³n de modelos con mÃ©tricas AUC-ROC y F1-score. Interpretabilidad mediante SHAP y Feature Importance (Gain).
Deployment & PrÃ³ximos pasos
Plan de despliegue en producciÃ³n, monitoreo de drift, automatizaciÃ³n de campaÃ±as y retraining trimestral.

Resultados destacados
Mejor modelo: XGBoost con AUC-ROC de 0.92 y F1-score de 0.80.
Variables mÃ¡s importantes: TotalCharges, Tenure, MonthlyCharges.
Recomendaciones de negocio: campaÃ±as personalizadas a clientes con churn_prob > 0.7.
ðŸ’¾
Reproducibilidad
Clonar el repositorio:
git clone https://github.com/tu-usuario/tu-repo-churn.git
cd tu-repo-churn
Instalar dependencias:
pip install -r requirements.txt
Ejecutar el notebook:
Abrir notebook/rivadeneira_maria_churn.ipynb y correr "Restart & Run All".